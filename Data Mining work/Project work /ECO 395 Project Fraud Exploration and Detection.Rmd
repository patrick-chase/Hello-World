---
title: 'ECO 395 Project: Fraud Exploration and Detection'
author: "Patrick Chase"
date: "5/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      include = FALSE,
                      message = FALSE, 
                      warning = FALSE)
```
# Intro and Data Overview

```{r data load and sampling}
# link to original data - https://www.kaggle.com/c/ieee-fraud-detection/data 
# I chose to sample these files for two reasons. The first is that Github has limits on the size of the repository, and I wanted to make running my code relatively easy. The second is I'm operating with limited system. A small sample sped up processing times on my system. If one wanted to replicate this work with the full files you could skip this chunk and work direclty with the full files. 
install.packages("dplyr")
library(readr)
library(dplyr)
## Training data set merge and sampling
train_transaction <- read_csv("~/Desktop/GitHub/ECO395-Fraud-Data/Fraud Data/ieee-fraud-detection/train_transaction.csv")
train_identity <- read_csv("~/Desktop/GitHub/ECO395-Fraud-Data/Fraud Data/ieee-fraud-detection/train_identity.csv")

##Here I'm merging the two training data sets and then selecting a random sample that is equal to 20% of the original training set. 

fraud_train_full <- merge(train_transaction, train_identity, by ="TransactionID")

fraud_train_sample <- sample_frac(fraud_train_full, size = .2, replace = FALSE)

write.csv(fraud_train_sample, "~/Desktop/fraud_train_sample", row.names = TRUE)





```

